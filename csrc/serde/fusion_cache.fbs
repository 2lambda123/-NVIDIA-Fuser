// clang-format off
/*
 * SPDX-FileCopyrightText: Copyright (c) 2023-present NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved.
 * SPDX-License-Identifier: BSD-3-Clause
 */
namespace nvfuser.serde;

// This indicates the flatbuffer compatibility. The number will bump up when a
// breaking change is applied to the schema.
file_identifier "NV00";

// =====================================================================================
// Enum definitions

enum ArgType:int {
  PhiloxCudaState,
  Long,
  Double,
  ComplexDouble,
  Bool,
  Tensor,
  CpuScalarTensor
}

enum KernelIndexMode:int {
  INT32,
  INT64
}

// Datatype enum represents the data type of a Tensor, Scalar, or Function.
enum DataType:int {
    Double = 0,
    Float,
    Half,
    Int,
    Int32,
    Bool,
    BFloat16,
    ComplexFloat,
    ComplexDouble,
    None
}

// The StateType enum is used to indicate the whether the state object is a
// Scalar or Tensor.
enum StateType:int {
    Tensor = 0,
    Scalar,
    None,
}

enum Contiguity:int {
    Strided = 0,
    Contiguous,
    None,
}

// Each RecordFunctor is assigned a RecordType for the hash function.
// Otherwise, the record type is determined via the success of dynamic casting.
// We enumerate the template arguments of a RecordFunctor, so we can specify
// them during deserialization.
enum RecordType:int {
    Base = 0,
    BatchNormOp,
    BroadcastOp,
    BroadcastInDim,
    BroadcastInDimSymbolic,
    CastTv,
    CastVal,
    CatOp,
    ConstantBool,
    ConstantInt,
    ConstantDouble,
    ConstantComplexDouble,
    End,
    FullOp,
    IotaOp,
    IndexSelectOp,
    TorchGatherOp,
    Unary_TV,
    Unary_VAL,
    Binary_TV,
    Binary_VAL,
    Binary_TV_VAL,
    Binary_VAL_TV,
    Ternary_TV,
    Ternary_VAL,
    Ternary_TV_TV_VAL,
    Ternary_TV_VAL_TV,
    Ternary_VAL_TV_TV,
    Ternary_VAL_VAL_TV,
    Ternary_TV_VAL_VAL,
    Ternary_VAL_TV_VAL,
    Ternary_Alpha_TV,
    Ternary_Alpha_VAL,
    Ternary_Alpha_TV_TV_VAL,
    Ternary_Alpha_TV_VAL_TV,
    Ternary_Alpha_VAL_TV_TV,
    Ternary_Alpha_VAL_VAL_TV,
    Ternary_Alpha_TV_VAL_VAL,
    Ternary_Alpha_VAL_TV_VAL,
    OutputTv,
    OutputVal,
    PadOp,
    PermuteOp,
    RandomOp,
    ReductionMax,
    ReductionMin,
    ReductionProd,
    ReductionSum,
    ReshapeOp,
    Scalar,
    SliceOp,
    SqueezeOp,
    Start,
    Tensor,
    TensorSizes,
    VarianceOp,
    VarianceMeanOp,
}

// =====================================================================================
// Union definitions

// The RecordData hold the attribute information for each Record Functor.
union RecordData {
  BatchNorm,
  Bool,
  Broadcast,
  BroadcastInDim,
  BroadcastInDimSymbolic,
  ComplexDouble,
  Double,
  Dtype,
  Dimension,
  Int,
  Norm,
  Output,
  Pad,
  Permute,
  Slice,
  Squeeze,
  Reduction,
  Reshape,
  Tensor,
  TensorCreation,
  TensorCreationSymbolic,
}

union ArgAbstractData {
  Bool,
  ComplexDouble,
  Double,
  Int,
  PhiloxCudaState,
  TensorArg,
  CpuScalar
}

union CpuScalarData {
  Bool,
  ComplexDouble,
  Double,
  Int,
}

// =====================================================================================
// Basic data tables

// Data for Constant Bool
table Bool {
  bool_val: bool;
}

// Data for Constant Double, Float, Half, BFloat16
table Double {
  double_val: double;
  dtype: DataType;
}

// Data for Constant Int or Long
table Int {
  int_val: long;
  dtype: DataType;
}

// Data for Constant Complex Double or Float
table ComplexDouble {
  real: double;
  imag: double;
  dtype: DataType;
}

//
// =====================================================================================

table CpuScalar {
  data : CpuScalarData;
}

table PhiloxCudaState {
  seed : ulong;
  offset : ulong;
}

table TensorArg {
  alignment_size : ulong;
  size : [long];
  stride : [long];
  ndims : long;
  dtype: DataType;
}

table ArgAbstract {
  type : ArgType;
  data  : ArgAbstractData;
}

table KernelArgumentHolder {
  arguments : [ArgAbstract];
  device_index : byte;
  cache_id : ulong;
  index_mode : KernelIndexMode;
}

table TensorShape {
  shape : [long];
}

table LaunchParams {
  gdimx : long;
  gdimy : long;
  gdimz : long;
  bdimx : long;
  bdimy : long;
  bdimz : long;
  smem : long;
  output_sizes : [TensorShape];
}

table CompileParams {
  index_type : DataType;
  maxrregcount : int;
  enable_magic_zero : bool;
}

// CUmodule module
// CUfunction function
table NvrtcFunction {
  module : [byte];
  function : [byte];
}

table GlobalBufferInfo {
  sizes : [long];
  strides : [long];
  type : DataType;
  zero_init : bool;
  is_profile_buffer : bool;
}

table ExecutorEntry {
    init : bool;
    launch_params : LaunchParams;
    // Aliased output and input mappings
    output_aliases : [int];
    input_aliases : [int];
    outputs : [GlobalBufferInfo];
    intermediates : [GlobalBufferInfo];
    rand_offset : ulong;
}

// Do not serialize if there is misaligned vectorized tensors.
table VectorizedTensorInfo {
  // Aligned vectorized fusion inputs
  aligned_vectorized_inp_tensor_pos : [long];

  // Aligned vectorized fusion outputs
  aligned_vectorized_out_tensor_pos : [long];

  // Track which tensor views are inputs or outputs of a vectorized operation
  // and their maximum vectorized access size.
  // Analogous to map<TensorView*, int> kernel_summary.vectorized_accesses.
  aligned_vectorized_inp_tensor_word_size : [long];
  aligned_vectorized_out_tensor_word_size : [long];
}

table KernelSummary {
  // Indicate the need to generate random numbers
  max_rng_offsets : int = -1;

  // Do we have any grid reduction in a loop, or grid reductions dependent on grid reductions
  has_cooperative_grid_reduction : bool;

  // ceilDiv extents that must be divisible
  lhs_splits_to_validate : [long];
  rhs_splits_to_validate : [long];

  // Track information on vectorized set operations for runtime validation
  vectorized_set_info : VectorizedTensorInfo;
}

// =====================================================================================
// RecordData tables for RecordFunctor objects

// Data for BatchNormOpRecord
table BatchNorm {
  training: bool;
  channels_last: bool;
}

// Data for BroadcastOpRecord
table Broadcast {
  broadcast_dims: [bool];
}

// Data for BroadcastInDimOpRecord<int64_t>
table BroadcastInDim {
  output_shape: [long];
  broadcast_dims: [long];
}

// Data for BroadcastInDimOpRecord<nvfuser::State>
table BroadcastInDimSymbolic {
  output_shape: [State];
  broadcast_dims: [long];
}

// Data for CastOpRecord, ScalarRecord, and IotaOpRecord
table Dtype {
  dtype: DataType;
}

// Data for TorchGatherOpRecord and IndexSelectOpRecord
table Dimension {
  dim: long;
}

// Data for NormOpRecord
table Norm {
  axes: [int];
  correction: long;
  keep_dim: bool;
}

// Data for OutputRecord
table Output {
  stride_order: [long];
}

// Data for PadOpRecord
table Pad {
  pad_widths: [long];
}

// Data for PermuteOpRecord
table Permute {
  dims: [long];
}

// Data for ReductionOpRecord
table Reduction {
  axes: [int];
  keep_dim: bool;
  dtype: DataType;
}

// Data for ReshapeOpRecord
table Reshape {
  original_shape: [long];
  new_shape: [long];
}

// Data for SliceOpRecord
table Slice {
  start_indices: [long];
  end_indices:[long];
  strides: [long];
}

// Data for SqueezeOpRecord
table Squeeze {
  original_shape: [long];
  squeeze_dims: [long];
}

// Data for TensorRecord
table Tensor {
  sizes: [long];
  contiguity: [Contiguity];
  dtype: DataType;
  is_cpu: bool;
}

// Data for FullOpRecord
// The shape is defined with constant numbers.
table TensorCreation {
  shape: [long];
  dtype: DataType;
}

// Data for RandomOpRecord
// The shape is symbolic.
table TensorCreationSymbolic {
  shape: [State];
  dtype: DataType;
}

// =====================================================================================

// skipped potential fields:
// lowered : GpuLower
table FusionExecutor {
  configured_device_smem : ulong;
  maybe_available_smem : ulong;
  device_smem_limit: ulong;
  warp_size: int;
  fusion_id: int;
  // shared static value
  fusion_id_counter : int;
  kernel_code : string;
  executor_entry_lookup_keys : [ulong];
  executor_entry_lookup_values : [ExecutorEntry];
  compile_params : CompileParams;
  compiled_kernel : NvrtcFunction;
  launch_params : LaunchParams;
  kernel_summary : KernelSummary;
  used_tvs : [ulong];
}

// unscheduled_fusion : Fusion - defined by traversing Trie in FusionCache
table FusionKernelRuntime {
  args : KernelArgumentHolder;
  executors : [FusionExecutor];
  device : ulong;
}

struct EncodingEntry {
  id: ulong;
  lru_iter: ulong;
}

table InputsIdLookup {
  max_cache_size : ulong;
  currrent_id : ulong;
  lru_cache : [string];

  // define map<std::string, EncodingEntry> encoding_lookup
  encoding_lookup_keys : [string];
  encoding_lookup_values : [EncodingEntry];
}

// implicit fields
// unscheduled_fusion : Fusion - defined by traversing Trie in FusionCache
table FusionExecutorCache {
  inputs_cache : InputsIdLookup;

  // define map<size_t, vector<FusionKernelRuntime>> kernel_runtimes
  kernel_runtimes_keys : [ulong];
  kernel_runtimes_values : [FusionKernelRuntime];

  // define map<size_t, FusionKernelRuntime> id_to_kernel_runtime
  kernel_cache_keys : [ulong];
  // indices into kernel_runtime_values
  kernel_cache_values : [ulong];
}

// The State struct represents each scalar and tensor value.
// e.g., all input, output and intermediate values in the fusion.
struct State {
  index: int;
  type: StateType;
}

// RecordFunctor is represents operations in the Fusion. It is a node in the
// graph with input and output edges. Some operations require storing extra
// attributes in the RecordData field.
table RecordFunctor {
  args: [State];
  outputs: [State];
  name: string;
  type: RecordType;
  data: RecordData;
}

// The trie node is represents a Node in the trie structure.
// Only the terminal leaf nodes have cached fusions.
table TrieNode {
  record: RecordFunctor;
  children: [ulong];
  fusion_id: ulong;
  visits: ulong;
  is_terminal: bool;
}

// The fusion cache is a prefix tree (trie) of records that caches fusions in
// its leaves. For serialization, we flatten the trie structure using
// breadth-first search.
//
// skipped potential fields because we need to serialize the schedule operations.
// fusion_schedules
// user_def_input_encodings
table FusionCache {
  max_fusions: ulong;
  structure: [TrieNode];
  terminal_nodes: [ulong];
  auto_gen_schedules : [FusionExecutorCache];
}

root_type FusionCache;
