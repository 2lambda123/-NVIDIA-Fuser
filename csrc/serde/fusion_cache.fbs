// clang-format off
/*
 * SPDX-FileCopyrightText: Copyright (c) 2023-present NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved.
 * SPDX-License-Identifier: BSD-3-Clause
 */
namespace nvfuser.serde;

// This indicates the flatbuffer compatibility. The number will bump up when a
// breaking change is applied to the schema.
file_identifier "NV00";

// =====================================================================================
// Enum definitions

// Datatype enum represents the data type of a Tensor, Scalar, or Function.
enum DataType: int {
    None = 0,
    Double,
    Float,
    Half,
    Index,
    Int,
    Int32,
    Bool,
    BFloat16,
    ComplexFloat,
    ComplexDouble,
}

// The StateType enum indicates whether the state object is a Scalar or Tensor.
enum StateType: int {
    None = 0,
    Scalar,
    Vector,
    Tensor,
}

// The Contiguity enum shows whether a tensor dimension is contiguous
// with the dimension to its right.
enum Contiguity: int {
    None = 0,
    Strided,
    Contiguous,
}

// Each RecordFunctor is assigned a RecordType for the hash function.
// Otherwise, the record type is determined via the success of dynamic casting.
// We enumerate the template arguments of a RecordFunctor, so we can specify
// them during deserialization.
enum RecordType: int {
    Base = 0,
    AtOp,
    BatchNormOp,
    BroadcastOp,
    BroadcastInDim,
    CastTv,
    CastVal,
    CatOp,
    End,
    FullOp,
    IotaOp,
    IndexSelectOp,
    TorchGatherOp,
    TakeAlongAxisOp,
    Unary_TV,
    Unary_VAL,
    Binary_TV,
    Binary_VAL,
    Binary_TV_VAL,
    Binary_VAL_TV,
    Ternary_TV,
    Ternary_VAL,
    Ternary_TV_TV_VAL,
    Ternary_TV_VAL_TV,
    Ternary_VAL_TV_TV,
    Ternary_VAL_VAL_TV,
    Ternary_TV_VAL_VAL,
    Ternary_VAL_TV_VAL,
    Ternary_Alpha_TV,
    Ternary_Alpha_VAL,
    Ternary_Alpha_TV_TV_VAL,
    Ternary_Alpha_TV_VAL_TV,
    Ternary_Alpha_VAL_TV_TV,
    Ternary_Alpha_VAL_VAL_TV,
    Ternary_Alpha_TV_VAL_VAL,
    Ternary_Alpha_VAL_TV_VAL,
    OutputTv,
    OutputVal,
    PadOp,
    PermuteOp,
    StrideOrderOp,
    RandomOp,
    ReductionMax,
    ReductionMin,
    ReductionProd,
    ReductionSum,
    ReshapeOp,
    Scalar,
    ShapeOp,
    SizeOp,
    SliceOp,
    SqueezeOp,
    Start,
    Tensor,
    TensorSizes,
    VarianceOp,
    VarianceMeanOp,
    Vector,
}

enum UnaryOpType: int {
  None = 0,
  Cast,
  Neg,
}

enum BinaryOpType: int {
  None = 0,
  Add,
  CeilDiv,
  Div,
  Mod,
  Mul,
  Sub,
}

enum Swizzle2DType: int {
  None = 0,
  ZShape,
  Xor,
  Shift,
}

enum SwizzleMode: int {
  None = 0,
  Data,
  Loop,
}

enum IterType: int {
  Iteration = 0,
  Reduction,
  Broadcast,
  Gather,
  Stride,
  GatherScatter,
  VectorComponent,
  Symbolic,
}

// =====================================================================================
// Union definitions

// The RecordData hold the attribute information for each Record Functor.
union RecordData {
  At,
  BatchNorm,
  Broadcast,
  BroadcastInDim,
  Dimension,
  Dtype,
  Norm,
  Output,
  Pad,
  Dims,
  Slice,
  Squeeze,
  Reduction,
  Scalar,
  Size,
  Tensor,
  TensorCreation,
  TensorCreationSymbolic,
  Vector,
}

// The PolymorphicValueData union holds the attribute information for each PolymorphicValue.
union PolymorphicValueData {
  Scalar,
  ScalarCpu,
  TensorArg,
}

// The Instruction union holds the attribute information for each Instruction in NaiveValueGenerator.
union InstructionData {
  BinaryOp,
  GetAttr,
  GetItem,
  GetMetaData,
  IterDomain,
  Merge,
  NamedScalar,
  Resize,
  Scalar,
  Split,
  Swizzle2D,
  Symbolic,
  UnaryOp,
}

// =====================================================================================
// Basic data tables

// The State struct represents each scalar and tensor value.
// e.g., all input, output and intermediate values in the fusion.
struct State {
  index: int;
  type: StateType;
}

// Data for Scalar
table Scalar {
  dtype: DataType;
  has_value: bool;
  value_type: DataType;
  bool_value: bool;
  long_value: long;
  double_value: double;
  real_value: double;
  imag_value: double;
}

//
// =====================================================================================
// Tables for NaiveValueGenerator and AllocateBuffer used in FusionExecutor.

table BinaryOp {
  binary_type: BinaryOpType;
  src0: long;
  src1: long;
  out: long;
  name: string;
}

table GetAttr {
  struct: long;
  attr: string;
  out: long;
}

table GetItem {
  array: long;
  index: long;
  out: long;
}

table GetMetaData {
  in: long;
  out: long;
}

table Merge {
  inner: long;
  outer: long;
  out: long;
}

table NamedScalar {
  name: string;
}

table Resize {
  in: long;
  left_expansion: long;
  right_expansion: long;
  out: long;
}

table Split {
  in: long;
  factor: long;
  inner: long;
  outer: long;
  inner_split: bool;
  trim_out_of_bounds: bool;
}

table Swizzle2D {
  in_x: long;
  in_y: long;
  swizzle_type: Swizzle2DType;
  swizzle_mode: SwizzleMode;
  out_x: long;
  out_y: long;
}

table Symbolic {
  src0: long;
  name: string;
}

table UnaryOp {
  unary_type: UnaryOpType;
  data_type: DataType;
  src0: long;
  out: long;
  name: string;
}

table Instruction {
  data: InstructionData;
}

// NaiveValueGenerator creates Fusion IR values
table NaiveValueGenerator {
  instructions: [Instruction];
}

// The extent maps to an instruction in the NaiveValueGenerator.
table IterDomain {
  start: long;
  extent: long;
  out: long;
  parallel_type: int;
  iter_type: int;
  is_rfactor_domain: bool;
  is_padded_dimension: bool;
  is_mma_swizzled: bool;
}

// Table represents a single TensorView domain
table Domain {
  dims: [long];
}

// Table represents nvfuser::TensorView
table SymbolicTensor {
  dtype: DataType;
  root: Domain;
  rfactor: Domain;
  allocate: Domain;
  leaf: Domain;
}

// Table represents kir::Allocate node
table AllocateBuffer {
  tv: SymbolicTensor;
  shape: [long];
  zero_init: bool;
}

// =====================================================================================
// Tables for PolymorphicValue, ScalarCpu, TensorArg, KernelArgumentHolder used in FusionExecutor.

// The ScalarCpu is represented by a fixed size array of raw bytes.
table ScalarCpu {
  scalar_value: Scalar;
}

// Data of TensorArg.
// The original cpp TensorArg holds real data.
// However, only a metadata tensor is returned upon deserialization.
// The ptr parameter is used to determine vectorization during scheduling.
table TensorArg {
  ptr: ulong;
  sizes: [long];
  strides: [long];
  dtype: DataType;
}

// This table corresponds with a given PolymorphicValue object.
table PolymorphicValue {
  data: PolymorphicValueData;
}

// This table holds multiple PolymorphicValue objects.
table KernelArgumentHolder {
  arguments: [PolymorphicValue];
  device_index: byte;
  cache_id: ulong;
}

//
// =====================================================================================
// Tables for LaunchParams, GlobalBufferInfo, ExecutorEntry, and TensorShape used in FusionExecutor

// Data representing a tensor shape used in LaunchParam
table TensorShape {
  shape: [long];
}

// This table holds the cached launch parameters for a kernel.
table LaunchParams {
  gdimx: long;
  gdimy: long;
  gdimz: long;
  bdimx: long;
  bdimy: long;
  bdimz: long;
  smem: long;
  output_sizes: [TensorShape];
}

// This table describes the cached global buffers for a kernel.
// The original cpp GlobalBufferInfo contains a TensorView pointer.
// For this table, we represent the pointer with an integer position.
// For output tensors, we use its position in the fusion outputs.
// For intermediate tensors, we use its position in the KernelSummary global_allocations.
table GlobalBufferInfo {
  tv: long = -1;
  sizes: [long];
  strides: [long];
  dtype: DataType;
  zero_init: bool;
  is_profile_buffer: bool;
  is_fusion_output: bool;
}

// This table describes the cached ExecutorEntry for a kernel.
table ExecutorEntry {
    init: bool;
    launch_params: LaunchParams;
    // Aliased output and input mappings
    output_aliases: [int];
    input_aliases: [int];
    outputs: [GlobalBufferInfo];
    intermediates: [GlobalBufferInfo];
}

// =====================================================================================
// RecordData tables for RecordFunctor objects

// Data for AtOpRecord
table At {
  index: long;
}

// Data for BatchNormOpRecord
table BatchNorm {
  training: bool;
  channels_last: bool;
}

// Data for BroadcastOpRecord
table Broadcast {
  broadcast_dims: [bool];
}

// Data for BroadcastInDimOpRecord
table BroadcastInDim {
  output_size: ulong;
  broadcast_dims: [long];
}

// Data for CastOpRecord, ScalarRecord, and IotaOpRecord
table Dtype {
  dtype: DataType;
}

// Data for TorchGatherOpRecord, TakeAlongAxisOpRecord, and IndexSelectOpRecord
table Dimension {
  dim: long;
}

// Data for NormOpRecord
table Norm {
  axes: [int];
  correction: long;
  keep_dim: bool;
}

// Data for OutputRecord
table Output {
  stride_order: [long];
}

// Data for PadOpRecord
table Pad {
  pad_widths: [long];
}

// Data for DimsOpRecord
table Dims {
  dims: [long];
}

// Data for ReductionOpRecord
table Reduction {
  axes: [int];
  keep_dim: bool;
  dtype: DataType;
}

// Data for SizeOpRecord
table Size {
  dim: long;
}

// Data for SliceOpRecord
table Slice {
  start_indices: [long];
  end_indices:[long];
  strides: [long];
}

// Data for SqueezeOpRecord
table Squeeze {
  original_shape: [long];
  squeeze_dims: [long];
}

// Data for TensorRecord
table Tensor {
  sizes: [long];
  contiguity: [Contiguity];
  stride_order: [long];
  dtype: DataType;
  is_cpu: bool;
}

// Data for FullOpRecord
// The shape is defined with constant numbers.
table TensorCreation {
  shape: [long];
  dtype: DataType;
}

// Data for RandomOpRecord
// The shape is symbolic.
table TensorCreationSymbolic {
  shape: [State];
  dtype: DataType;
}

// Data for Vector
table Vector {
  dtype: DataType;
}

// =====================================================================================
//

// This table stores the KernelSummary value necessary for running compiled fusion.
table KernelSummary {
  has_cooperative_grid_reduction: bool;
  has_dynamic_local_memory_allocations: bool;
  has_block_reductions: bool;
  has_grid_reductions: bool;
  has_block_broadcasts: bool;
  has_grid_broadcasts: bool;
  has_block_welford: bool;
  has_grid_welford: bool;
  has_outer_grouped_grid_welford: bool;
  largest_smem_data_type: DataType;
  outer_grouped_grid_welford_largest_smem_size: int = 0;
  generator: NaiveValueGenerator;
  global_allocations: [AllocateBuffer];
}

// Each CudaKernel represents a single, compiled kernel.
table CudaKernel {
  kernel_name: string;
  compile_args: string;
  cubin: [ubyte];
  cubin_filename: string;
  ptx: [ubyte];
  ptx_filename: string;
  // The block size field is used to generate compile arguments.
  // We compare the generated compile args against those stored in this table
  // when deserializing this cuda kernel.
  block_size: long = -1;
}

// Each Fusion Executor maps to a lowered and compiled kernel.
table FusionExecutor {
  device_smem_limit: long;
  block_size_high_water_mark: long;
  maxrregcount_high_water_mark: long;
  warp_size: long;
  fusion_id: long;
  fusion_id_counter : long;
  kernel_code : string;
  executor_entry_lookup_keys : [ulong];
  executor_entry_lookup_values : [ExecutorEntry];
  // Is this kernel being compiled with int32 or int64 indexing?
  index_type : DataType;
  summary: KernelSummary;
  compiled_kernel: CudaKernel;
}

// Each FusionKernelRuntime represents a concretized, segmented Fusion.
// We store the metadata for the original arguments to segment, schedule, and compile the Fusion at deserialization.
// Each fusion segment is given a FusionExecutor.
// The unscheduled fusion is defined by traversing Trie in FusionCache.
table FusionKernelRuntime {
  args: KernelArgumentHolder;
  executors: [FusionExecutor];
}

// EncodingEntry for InputsIdLookup LRU cache.
struct EncodingEntry {
  id: ulong;
  lru_iter: ulong;
}

// This table is a LRU cache containing input arguments known by the FusionExecutorCache.
table InputsIdLookup {
  max_cache_size: ulong;
  current_id: ulong;
  lru_cache: [string];

  // This field defines map<std::string, EncodingEntry> encoding_lookup
  encoding_lookup_keys: [string];
  encoding_lookup_values: [EncodingEntry];
}

// This table represents a key-value pair in the kernel_runtimes map in FusionExecutorCache.
table KernelRuntimeState {
  device_id: ulong;
  has_dynamic_transform_info: bool;
  runtimes: [FusionKernelRuntime];
}

// This table describes the FusionExecutorCache.
// The unscheduled fusion is defined by traversing Trie in FusionCache.
table FusionExecutorCache {
  inputs_cache: InputsIdLookup;

  // This field represents a map<<size_t, DynamicTransformConcretizationInfo>, vector<FusionKernelRuntime>>.
  // DynamicTransformConcretizationInfo is regenerated during deserialization.
  kernel_runtimes_map: [KernelRuntimeState];

  // This field defines a map<size_t, FusionKernelRuntime> id_to_kernel_runtime.
  kernel_cache_keys: [ulong];
  // indices into kernel_runtime_values
  kernel_cache_values: [ulong];
}

// RecordFunctor represents operations in the Fusion. It is a node in the graph with input and output edges.
// Some operations require storing extra attributes in the RecordData field.
table RecordFunctor {
  args: [State];
  outputs: [State];
  name: string;
  type: RecordType;
  data: RecordData;
}

// The trie node is represents a Node in the trie structure.
// Only the terminal leaf nodes have cached fusions.
table TrieNode {
  record: RecordFunctor;
  children: [ulong];
  fusion_id: ulong;
  visits: ulong;
  is_terminal: bool;
}

// The fusion cache is a prefix tree (trie) of records that caches fusions in
// its leaves. For serialization, we flatten the trie structure using
// breadth-first search.
//
// TODO We skipped these fields required for user-defined schedulers
// * fusion_schedules
// * user_def_input_encodings
table FusionCache {
  max_fusions: ulong;
  structure: [TrieNode];
  terminal_nodes: [ulong];
  auto_gen_schedules: [FusionExecutorCache];
}

root_type FusionCache;
